{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Codecs and PersonCodec Classes\n",
    "\n",
    "`Codecs` is a container class for managing ParlaCLARIN categorical (key/value) data i.e. mappings of integer data to text data. It exposes the data itself (as a number of Pandas dataframes), and a set of utility functions for working with the data e.q. encoding & decoding data.\n",
    "\n",
    "| Table           | Id                 | Description              |\n",
    "| --------------- | ------------------ | ------------------------ |\n",
    "| chamber         | chamber_id         | List of chambers         |\n",
    "| gender          | gender_id          | List of genders          |\n",
    "| government      | government_id      | List of governments      |\n",
    "| party           | party_id           | List of partys           |\n",
    "| office_type     | office_type_id     | List of office types     |\n",
    "| sub_office_type | sub_office_type_id | List of sub office types |\n",
    "\n",
    "`PersonCodecs` is a derived class that also include individual data from the `persons_of_interest`. This is a processed version of information found in `person.csv` metadata, and includes only personons that has speeches in the corpus, and with some additional columns.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TrendData class\n",
    "\n",
    "The `riksprot.TrendsData` class computes word trends using filters and pivot keys found in the `PersonCodecs` container. It is based on the `penelope.TrendsData` class with some minor additions.\n",
    "\n",
    "The class has the following data members:\n",
    "\n",
    "| Member             | Type              | Description                         |\n",
    "| ------------------ | ----------------- | ----------------------------------- |\n",
    "| corpus             | VectorizedCorpus  | Original source corpus              |\n",
    "| compute_opts       | TrendsComputeOpts | Current compute options (see below) |\n",
    "| transformed_corpus | VectorizedCorpus  | Transformed (computed) corpus       |\n",
    "| n_top              | int               | Top count constraint                |\n",
    "| person_codecs      | PersonCodecs      | Codecs helper class                 |\n",
    "| tabular_compiler   | TabularCompiler   | Result compiler                     |\n",
    "| _gof_data_         | _GofData_         | _Godness of fit data (ignore)_      |\n",
    "\n",
    "And the following methods:\n",
    "\n",
    "| Method            | Signature                             | Description                                                                                                                                              |\n",
    "| ----------------- | ------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| transform         | _opts: TrendsComputeOpts -> self_     | Transforms `corpus` to `transformed_corpus` using `opts`                                                                                                 |\n",
    "| extract           | _(indices, filters) -> pd.DataFrame_  | Extract pd.DataFrame using current compiler.                                                                                                             |\n",
    "| reset             | _\\_ -> self_                          | Reset corpus and compute opts to default                                                                                                                 |\n",
    "| find_word_indices | _opts -> sequence[int]_               | Find indicies for matching words (accepts wildcards and regex). Delegates to `transform_corpus.find_matching_words_indices(opts.words, opts.top_count)`. |\n",
    "| find_words        | _opts -> sequence[str]_               | Find matching words (accepts wildcards and regex). Delegates to `transform_corpus.find_matching_words(opts.words, opts.top_count)`.                      |\n",
    "| get_top_terms     | _(int,kind,category) -> pd.DataFrame_ |\n",
    "\n",
    "The avaliable `ComputeOpts` attributes are:\n",
    "\n",
    "| Attribute           | Type                       | Description                                                    |\n",
    "| ------------------- | -------------------------- | -------------------------------------------------------------- |\n",
    "| normalize           | bool                       | Normalize data flag.                                           |\n",
    "| keyness             | pk.KeynessMetric           | Keyness metric to use `TF`, `TF (norm)` or `TF-IDF`            |\n",
    "| temporal_key        | str                        | Temporal pivot key: `year`, `lustrum` or `decade`              |\n",
    "| pivot_keys_id_names | list[str]                  | List of pivot key ID names                                     |\n",
    "| filter_opts         | `PropertyValueMaskingOpts` | Key/value filter of resulting data (extract)                   |\n",
    "| unstack_tabular     | bool                       | Unstack result i.e. return columns instead of categorical rows |\n",
    "| fill_gaps           | bool                       | Fill empty/missing temporal category values                    |\n",
    "| smooth              | bool                       | Return smoothed, interpolated data (for line plot)             |\n",
    "| top_count           | int                        |\n",
    "| words               | list[str]                  | List of word/patterns of interest                              |\n",
    "| descending          | bool                       | Result sort order                                              |\n",
    "| keyness_source      | pk.KeynessMetricSource     | Ignore (only valid for co-occurrence trends)                   |\n",
    "\n",
    "The avaliable `ComputeOpts` attributes are:\n",
    "\n",
    "| Method             | Signature                          | Description                                           |\n",
    "| ------------------ | ---------------------------------- | ----------------------------------------------------- |\n",
    "| invalidates_corpus | _other: TrendsComputeOpts -> bool_ | Checks if `other` opts invalidates transformed corpus |\n",
    "| clone              | \\*\\_ -> TrendsComputeOpts          | Creates a clone                                       |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load a DTM corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-24 16:05:00.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpenelope.vendor.gensim_api._gensim._models\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mgensim not included in current installment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import __paths__\n",
    "\n",
    "from parlaclarin import codecs as md\n",
    "from parlaclarin.trends_data import SweDebTrendsData, SweDebComputeOpts\n",
    "from penelope.common.keyness import KeynessMetric\n",
    "from penelope.corpus import VectorizedCorpus\n",
    "from penelope.utility import PropertyValueMaskingOpts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1500)\n",
    "\n",
    "dtm_folder: str = \"../data/dataset-01/v0.6.0/dtm/lemma\"\n",
    "dtm_tag: str = \"lemma\"\n",
    "\n",
    "corpus: VectorizedCorpus = VectorizedCorpus.load(folder=dtm_folder, tag=dtm_tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus metadata (speakers and codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  year_of_birth  year_of_death  has_multiple_parties   gender party_abbrev person_id\n",
      "person_id                                                                                                        \n",
      "Q53707          Tage Erlander           1901           1985                     0      man            S    Q53707\n",
      "Q5887636    Rune B. Johansson           1915           1982                     0      man            S  Q5887636\n",
      "unknown                                    0              0                     0  unknown            ?   unknown\n",
      "Q1606431         Henry Allard           1911           1996                     0      man            S  Q1606431\n",
      "Q707581    Ingemund Bengtsson           1919           2000                     0      man            S   Q707581\n",
      "                         name  year_of_birth  year_of_death  has_multiple_parties   gender party_abbrev person_id\n",
      "person_id                                                                                                        \n",
      "Q53707          Tage Erlander           1901           1985                     0      man            S    Q53707\n",
      "Q5887636    Rune B. Johansson           1915           1982                     0      man            S  Q5887636\n",
      "unknown                                    0              0                     0  unknown            ?   unknown\n",
      "Q1606431         Henry Allard           1911           1996                     0      man            S  Q1606431\n",
      "Q707581    Ingemund Bengtsson           1919           2000                     0      man            S   Q707581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Can be used to create a GUI for selecting metadata properties and values for display, grouping and filtering'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "codecs: md.PersonCodecs = md.PersonCodecs().load(source=\"../data/dataset-01/v0.6.0//riksprot_metadata.db\")\n",
    "\n",
    "\"\"\" Speakers metadata with encoded ids \"\"\"\n",
    "persons: pd.DataFrame = codecs.persons_of_interest.head().copy()\n",
    "\n",
    "\"\"\"Decoded speakers' metadata\"\"\"\n",
    "print(codecs.decode(persons))\n",
    "\n",
    "\"\"\"Decode speakers' metadata but keep ids\"\"\"\n",
    "print(codecs.decode(persons, drop=False))\n",
    "\n",
    "\"\"\"Print specification of metadata properties (and actual data).\"\"\"\n",
    "\"\"\"Can be used to create a GUI for selecting metadata properties and values for display, grouping and filtering\"\"\"\n",
    "# print(codecs.property_values_specs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute word trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  party_id  sverige  jag\n",
      "0  1960         5        1    1\n",
      "1  1960         9        0    5\n",
      "2  1961         9        1    3\n",
      "3  1970         5        3   32\n",
      "4  1970         7        0   50\n",
      "   year  party_id  finland\n",
      "0  1960         5        0\n",
      "1  1960         9        0\n",
      "2  1961         9        0\n",
      "3  1970         5        1\n",
      "4  1970         7        0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Compute trends \n",
    "    - group by \"year\" (temporal key) and party\n",
    "    - return absolute frequencies (keyness=KeynessMetric.TF)\n",
    "    - do not normalize\n",
    "    - do not fill temporal gaps (items with zero frequency)\n",
    "    - do not smooth (interpolate values, adds additional categories)\n",
    "    - return atmost 100 words\n",
    "    - do not unstack tabular data (keep party as column)\n",
    "\"\"\"\n",
    "\n",
    "trends_data: SweDebTrendsData = SweDebTrendsData(corpus=corpus, person_codecs=codecs, n_top=100000)\n",
    "\n",
    "opts: SweDebComputeOpts = SweDebComputeOpts(\n",
    "    fill_gaps=False,\n",
    "    keyness=KeynessMetric.TF,\n",
    "    normalize=False,\n",
    "    pivot_keys_id_names=[\"party_id\"],\n",
    "    filter_opts=PropertyValueMaskingOpts(gender_id=2),\n",
    "    smooth=False,\n",
    "    temporal_key=\"year\",\n",
    "    top_count=100,\n",
    "    unstack_tabular=False,\n",
    "    words=None,\n",
    ")\n",
    "\n",
    "trends_data.transform(opts)\n",
    "\n",
    "opts.words = words=[\"sverige\", \"jag\"]\n",
    "\n",
    "# FIXME: Extend API so that extract can take a list of words \n",
    "trends: pd.DataFrame = trends_data.extract(indices=trends_data.find_word_indices(opts))\n",
    "\n",
    "print(trends.head())\n",
    "\n",
    "opts.words = words=[\"finland\", \"du\"]\n",
    "print(trends_data.extract(indices=trends_data.find_word_indices(opts)).head())\n",
    "\n",
    "\n",
    "# trends_data.transformed_corpus.find_matching_words_indices(\n",
    "#     word_or_regexp=[\"sverige\", \"jag\"], n_max_count=100, descending=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  party_id  jag  sverige\n",
      "0  1960         5    1        1\n",
      "1  1960         9    5        0\n",
      "2  1961         9    3        1\n",
      "3  1970         5   32        3\n",
      "4  1970         7   50        0\n",
      "   year  jag  sverige party_abbrev\n",
      "0  1960    1        1            L\n",
      "1  1960    5        0            S\n",
      "2  1961    3        1            S\n",
      "3  1970   32        3            L\n",
      "4  1970   50        0            M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 167]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Decode any encoded ids in the trends data frame\"\"\"\n",
    "\n",
    "picked_indices = trends_data.find_word_indices(opts)\n",
    "\n",
    "trends: pd.DataFrame = trends_data.extract(indices=picked_indices)\n",
    "\n",
    "print(trends.head())\n",
    "\n",
    "\"\"\"Decode any encoded ids in the trends data frame\"\"\"\n",
    "print(trends_data.person_codecs.decode(trends).head())\n",
    "\n",
    "# Find indices of picked words from corpus\n",
    "trends_data.transformed_corpus.find_matching_words_indices(\n",
    "    word_or_regexp=[\"sverige\", \"jag\"], n_max_count=100, descending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
