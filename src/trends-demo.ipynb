{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Codecs and PersonCodec Classes\n",
    "\n",
    "`Codecs` is a container class for managing ParlaCLARIN categorical (key/value) data i.e. mappings of integer data to text data. It exposes the data itself (as a number of Pandas dataframes), and a set of utility functions for working with the data e.q. encoding & decoding data.\n",
    "\n",
    "| Table | Id | Description |\n",
    "| ----- | ----- | ----- |\n",
    "| chamber | chamber_id | List of chambers |\n",
    "| gender | gender_id | List of genders |\n",
    "| government | government_id | List of governments |\n",
    "| party | party_id | List of partys |\n",
    "| office_type | office_type_id | List of office types |\n",
    "| sub_office_type | sub_office_type_id | List of sub office types |\n",
    "\n",
    "`PersonCodecs` is a derived class that also include individual data from the `persons_of_interest`. This is a processed version of information found in `person.csv` metadata, and includes only personons that has speeches in the corpus, and with some additional columns. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TrendData class\n",
    "\n",
    "The `riksprot.TrendsData` class computes word trends using filters and pivot keys found in the `PersonCodecs` container. It is based on the `penelope.TrendsData` class with some minor additions.\n",
    "\n",
    "The class has the following data members:\n",
    "\n",
    "| Member | Type | Description |\n",
    "| ----- | ----- | ----- |\n",
    "| corpus | VectorizedCorpus | Original source corpus |\n",
    "| compute_opts | TrendsComputeOpts | Current compute options (see below)  |\n",
    "| transformed_corpus | VectorizedCorpus | Transformed (computed) corpus |\n",
    "| n_top | int | Top count constraint |\n",
    "| person_codecs | PersonCodecs | Codecs helper class |\n",
    "| tabular_compiler | TabularCompiler | Result compiler |\n",
    "| *gof_data* | *GofData* | *Godness of fit data (ignore)* |\n",
    "\n",
    "And the following methods:\n",
    "\n",
    "| Method | Signature | Description |\n",
    "| ----- | ----- | ----- |\n",
    "| transform | *opts: TrendsComputeOpts -> self* | Transforms `corpus` to `transformed_corpus` using `opts` |\n",
    "| extract | *(indices, filters) -> pd.DataFrame* | Extract pd.DataFrame using current compiler. |\n",
    "| reset | *_ -> self* | Reset corpus and compute opts to default |\n",
    "| find_word_indices | *opts -> sequence[int]* | Find indicies for matching words (accepts wildcards and regex). Delegates to `transform_corpus.find_matching_words_indices(opts.words, opts.top_count)`. |\n",
    "| find_words | *opts -> sequence[str]* | Find matching words (accepts wildcards and regex). Delegates to `transform_corpus.find_matching_words(opts.words, opts.top_count)`. |\n",
    "| get_top_terms | *(int,kind,category) -> pd.DataFrame* | \n",
    "\n",
    "The avaliable `ComputeOpts` attributes are:\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "| ----- | ----- | ----- |\n",
    "| normalize | bool | Normalize data flag. |\n",
    "| keyness | pk.KeynessMetric | Keyness metric to use `TF`, `TF (norm)` or `TF-IDF` |\n",
    "| temporal_key | str | Temporal pivot key: `year`, `lustrum` or `decade` |\n",
    "| pivot_keys_id_names | list[str] | List of pivot key ID names |\n",
    "| filter_opts | `PropertyValueMaskingOpts` | Key/value filter of resulting data (extract) |\n",
    "| unstack_tabular | bool | Unstack result i.e. return columns instead of categorical rows |\n",
    "| fill_gaps | bool | Fill empty/missing temporal category values |\n",
    "| smooth | bool | Return smoothed, interpolated data (for line plot) |\n",
    "| top_count | int |\n",
    "| words | list[str] | List of word/patterns of interest |\n",
    "| descending | bool | Result sort order |\n",
    "| keyness_source | pk.KeynessMetricSource | Ignore (only valid for co-occurrence trends) |\n",
    "\n",
    "The avaliable `ComputeOpts` attributes are:\n",
    "\n",
    "| Method | Signature | Description |\n",
    "| ----- | ----- | ----- |\n",
    "| invalidates_corpus | *other: TrendsComputeOpts -> bool* | Checks if `other` opts invalidates transformed corpus |\n",
    "| clone | *_ -> TrendsComputeOpts | Creates a clone |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load a DTM corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-24 08:55:34.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpenelope.vendor.gensim_api._gensim._models\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mgensim not included in current installment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import __paths__\n",
    "\n",
    "from penelope.corpus import VectorizedCorpus\n",
    "\n",
    "dtm_folder: str = \"../data/dataset-01/v0.6.0/dtm/lemma\"\n",
    "dtm_tag: str = \"lemma\"\n",
    "\n",
    "corpus: VectorizedCorpus = VectorizedCorpus.load(folder=dtm_folder, tag=dtm_tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus metadata (speakers and codes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  year_of_birth  year_of_death  has_multiple_parties   gender party_abbrev person_id\n",
      "person_id                                                                                                        \n",
      "Q53707          Tage Erlander           1901           1985                     0      man            S    Q53707\n",
      "Q5887636    Rune B. Johansson           1915           1982                     0      man            S  Q5887636\n",
      "unknown                                    0              0                     0  unknown            ?   unknown\n",
      "Q1606431         Henry Allard           1911           1996                     0      man            S  Q1606431\n",
      "Q707581    Ingemund Bengtsson           1919           2000                     0      man            S   Q707581\n",
      "                         name  year_of_birth  year_of_death  has_multiple_parties   gender party_abbrev person_id\n",
      "person_id                                                                                                        \n",
      "Q53707          Tage Erlander           1901           1985                     0      man            S    Q53707\n",
      "Q5887636    Rune B. Johansson           1915           1982                     0      man            S  Q5887636\n",
      "unknown                                    0              0                     0  unknown            ?   unknown\n",
      "Q1606431         Henry Allard           1911           1996                     0      man            S  Q1606431\n",
      "Q707581    Ingemund Bengtsson           1919           2000                     0      man            S   Q707581\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from parlaclarin import codecs as md\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1500)\n",
    "\n",
    "metadata_filename: str = \"../data/dataset-01/v0.6.0//riksprot_metadata.db\"\n",
    "\n",
    "# Load codecs metadata\n",
    "codecs: md.PersonCodecs = md.PersonCodecs().load(source=metadata_filename)\n",
    "\n",
    "# Speakers metadata with encoded ids:\n",
    "persons: pd.DataFrame = codecs.persons_of_interest.head().copy()\n",
    "\n",
    "# Person metadata with decoded ids:\n",
    "print(codecs.decode(persons))\n",
    "\n",
    "# Person metadata with encoded and decoded ids:\n",
    "print(codecs.decode(persons, drop=False))\n",
    "\n",
    "# Specification of metadata properties (and actual data) avaliable for display, grouping and filtering\n",
    "# print(codecs.property_values_specs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute word trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parlaclarin.trends_data import SweDebTrendsData, SweDebComputeOpts\n",
    "from penelope.utility import PropertyValueMaskingOpts\n",
    "from penelope.common.keyness import KeynessMetric\n",
    "\n",
    "# Create trends data object\n",
    "trends_data: SweDebTrendsData = SweDebTrendsData(corpus=corpus, person_codecs=codecs, n_top=100000)\n",
    "\n",
    "# Define computation options\n",
    "opts: SweDebComputeOpts = SweDebComputeOpts(\n",
    "        fill_gaps=False,\n",
    "        keyness=KeynessMetric.TF,\n",
    "        normalize=False,\n",
    "        pivot_keys_id_names=['party_id'],\n",
    "        filter_opts=PropertyValueMaskingOpts(gender_id=2),\n",
    "        smooth=False,\n",
    "        temporal_key=\"year\",\n",
    "        top_count=100,\n",
    "        unstack_tabular=False,\n",
    "        words=[\"sverige\", \"jag\"],\n",
    "    )\n",
    "\n",
    "# Compute trends data\n",
    "trends_data.transform(opts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  party_id  jag  sverige\n",
      "0  1960         5    1        1\n",
      "1  1960         9    5        0\n",
      "2  1961         9    3        1\n",
      "3  1970         5   32        3\n",
      "4  1970         7   50        0\n",
      "   year  jag  sverige party_abbrev\n",
      "0  1960    1        1            L\n",
      "1  1960    5        0            S\n",
      "2  1961    3        1            S\n",
      "3  1970   32        3            L\n",
      "4  1970   50        0            M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 167]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find indices of picked words stored in opts\n",
    "picked_indices = trends_data.find_word_indices(opts)\n",
    "\n",
    "# Extract a data frame with the picked words\n",
    "trends: pd.DataFrame = trends_data.extract(indices=picked_indices)\n",
    "\n",
    "# Display the trends data frame\n",
    "print(trends.head())\n",
    "\n",
    "# Decode any encoded ids in the trends data frame   \n",
    "print(trends_data.person_codecs.decode(trends).head())\n",
    "\n",
    "# Find indices of picked words from corpus\n",
    "trends_data.transformed_corpus.find_matching_words_indices(\n",
    "        word_or_regexp=[\"sverige\", \"jag\"], n_max_count=100, descending=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus: VectorizedCorpus = VectorizedCorpus.load(folder=dtm_folder, tag=dtm_tag)\n",
    "\n",
    "def filter(corpus, px) -> VectorizedCorpus:\n",
    "\n",
    "    document_index: pd.DataFrame = corpus.document_index[corpus.document_index.apply(px, axis=1)]\n",
    "\n",
    "    indices = list(document_index.index)\n",
    "\n",
    "    corpus = VectorizedCorpus(\n",
    "        bag_term_matrix=corpus._bag_term_matrix[indices, :],\n",
    "        token2id=corpus.token2id,\n",
    "        document_index=document_index,\n",
    "        **corpus.payload,\n",
    "    )\n",
    "\n",
    "    return corpus\n",
    "\n",
    "filter(corpus, lambda w: w['year']==1995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_index: pd.DataFrame = corpus.document_index\n",
    "DocumentIndexHelper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
